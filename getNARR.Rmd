---
title: "Download NARR Data on Big Tornado Days"
author: "James Elsner"
date: "11/1/2018"
output: github_notebook
editor_options:
  chunk_output_type: console
---

## Part 1: Tornado data

Set working directory and load packages.
```{r}
library(tidyverse)
library(lubridate)
library(sf)
library(tmap)
library(USAboundaries)
library(rgeos)
```

The newest GIS shapefile contains missing geometries for more than 30% of the tornadoes. The number of missing geometries is highest after 1995. Instead here we use the csv file from https://www.spc.noaa.gov/wcm/#data  Use the start lon/lat and create a `sp` object then convert to `sf`. Set the coordinate reference system (crs) to ESPG 4326.
```{r}
Tor.df <- read.csv(file = "1950-2017_actual_tornadoes.csv")
Tor.spdf <- Tor.df
rm(Tor.df)
sp::coordinates(Tor.spdf) <- ~ slon + slat
Tor.sfdf <- st_as_sf(Tor.spdf)
st_crs(Tor.sfdf) <- 4326
```

Remove tornadoes in Hawaii, Alaska, and Puerto Rico and those occurring before 1994. That year marks the beginning of comprehensive WSR-88D radar. For missing EF ratings use the modification rules (if/else) defined here: https://www.spc.noaa.gov/wcm/OneTor_F-scale-modifications.pdf
```{r}
Tor.sfdf <- Tor.sfdf %>%
  filter(yr >= 1994,
         !st %in% c("AK", "PR", "HI")) %>%
  mutate(mag = ifelse(mag == -9 & len <= 5, 0, mag),
         mag = ifelse(mag == -9 & len > 5, 1, mag))
```

Add a data/time column also add columns for path length, width, and area in metric units. Leave the time zone as native CDT. Create a convective day (6AM to 6AM) column taking hours 00:00:00 -> 05:59:59 and assigning it to the previous date (this associates the previous day's date to tornadoes occurring up to 6 hours after local midnight).
```{r}
Tor.sfdf <- Tor.sfdf %>%
  mutate(dy = format(as.Date(date,format="%m/%d/%y"), "%d"),
         DateTime = as.POSIXct(paste(yr, mo, dy, time), format = "%Y%m%d%H:%M:%S"),
         Hour = hour(DateTime),
         Year = year(DateTime),
         cDateTime = DateTime - as.difftime(6, unit = "hours"),
         cDate = as.Date(as_datetime(ifelse(Hour < 6, (DateTime - 86400), cDateTime), tz = Sys.timezone())),
         Length = len * 1609.34,
         Length = ifelse(Length == 0, min(Length[Length > 0]), Length), #takes care of zero length
         Width = wid * .9144,
         Width = ifelse(Width == 0, min(Width[Width > 0]), Width), #takes care of zero width
         Width = ifelse(Year >= 1995, Width * pi/4, Width), #takes care of change: avg to max
         cas = inj + fat,
         AreaPath = Length * Width,
         Ma = factor(month.abb[mo], levels = month.abb[1:12])) %>%
  sf::st_sf()
max(Tor.sfdf$yr)
```

The geometry type is `POINT`. Each tornado is represented as a single point location geometry (start location). 

Add energy dissipation per tornado.
```{r}
perc <- c(1, 0, 0, 0, 0, 0, 
          .772, .228, 0, 0, 0, 0,
          .616, .268, .115, 0, 0, 0,
          .529, .271, .133, .067, 0, 0,
          .543, .238, .131, .056, .032, 0,
          .538, .223, .119, .07, .033, .017)
percM <- matrix(perc, ncol = 6, byrow = TRUE)
threshW <- c(29.06, 38.45, 49.62, 60.8, 74.21, 89.41)
midptW <- c(diff(threshW)/2 + threshW[-length(threshW)], threshW[length(threshW)] + 7.5)
ef <- Tor.sfdf$mag + 1
EW3 <- numeric()
for(i in 1:length(ef)) EW3[i] = midptW^3 %*% percM[ef[i], ]
Tor.sfdf <- Tor.sfdf %>%
  mutate(ED = EW3 * AreaPath)
```

Determine big days.
```{r}
BigDays.sfdf <- Tor.sfdf %>%
  group_by(cDate) %>%
  summarize(nT = n(),
            ATE = sum(ED),
            AvgATE = exp(mean(log(ED)))) %>%
  filter(nT >= 10)
dim(BigDays.sfdf)
```

Use a projection that matches the projection of the environmental data raster.
```{r}
BigDays.sfdfT <- st_transform(BigDays.sfdf, 
                              crs = "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

Get state borders and use the `tm_shape()` function.
```{r}
sts <- state.name[!state.name %in% c("Alaska", "Hawaii")]
stateBorders <- us_states(states = sts)

tm_shape(stateBorders) + 
  tm_borders(col = "grey") +
  tm_layout(legend.outside = TRUE) +
tm_shape(BigDays.sfdfT) +
  tm_dots() 
```

Pecentage of all tornadoes occurring on the big days.
```{r}
sum(BigDays.sfdfT$nT)/dim(Tor.sfdf)[1] * 100
```

Obtain the big day hulls.
```{r}
BigDayHulls.sfdfT <- st_buffer(st_convex_hull(BigDays.sfdfT), dist = 100000) 
coords <- st_coordinates(st_centroid(BigDays.sfdfT))
Area <- st_area(BigDayHulls.sfdfT)
BigDayHulls.sfdfT$Area <- Area
BigDayHulls.sfdfT$X <- coords[, 1]
BigDayHulls.sfdfT$Y <- coords[, 2]
```

Check on a map.
```{r}
tm_shape(BigDayHulls.sfdfT) +
  tm_polygons(alpha = .1) + 
tm_shape(stateBorders, projection = "laea_NA", is.master = TRUE) + 
  tm_borders()
```

Arrange by accumulated tornado energy (ATE).
```{r}
BigDays.sfdfT %>%
  top_n(ATE, n = 20) %>%
  arrange(desc(ATE))
```

Use a Spearman's correlation to quantify the relationship between ATE and the number of tornadoes.  
```{r}
cor.test(x = BigDays.sfdfT$ATE, y = BigDays.sfdfT$nT, method = 'spearman')
```

Density plot of ATE.
```{r}
labels <- c("10", "100", "1000","10000", "100000")

ggplot(BigDays.sfdfT, aes(log10(ATE))) +
  geom_histogram(binwidth = .5, color = "white") +
  scale_x_continuous(breaks = 10:14, labels= labels) +
  xlab("Accumulated Tornado Energy [GW]") +
  ylab("Frequency") +
  theme_minimal()
```

## Part 2: Environmental data

Get environmental data at 18Z (2p local) on the convective day. Set up a vector of URLs as character strings. Data are not available after September 30, 2014.
```{r}
library(lubridate)
df <- BigDayHulls.sfdfT %>%
  filter(cDate <= as.Date("2014-09-30")) %>%
  mutate(Yr = year(cDate),
         Mo = month(cDate),
         Month = format(cDate, "%m"), # this is needed to preserve the leading zeros
         Day = format(cDate, "%d"), 
         YrMo = paste0(Yr, Month),
         YrMoDa = paste0(YrMo, Day),
         slug2 = paste0(YrMo, "/", YrMoDa, "/", "narr-a_221_", YrMoDa, "_1800_000.grb"),
         slug = paste0("https://nomads.ncdc.noaa.gov/data/narr/", slug2)) 
slug <- df$slug
```

Download the grib files. ~ 2 hours to download 300 grb file.
```{r, eval=FALSE}
for(i in 1:length(slug)){
    download.file(slug[i], paste0("Archive/NARRdata", i, ".grb"), mode = "wb")
    }
```

Read the grib files as raster bricks and assign the CAPE and helicity variables to separate raster layers. Extract the average (and extreme) environmental values within each of the big days in large groups hulls. https://nomads.ncdc.noaa.gov/data/narr/201104/20110427/narr-a_221_20110427_0000_000.inv
```{r}
library(raster)
aCAPE <- numeric()
aHLCY <- numeric()
aCIN <- numeric()
aUSTM <- numeric()
aVSTM <- numeric()
aBS <- numeric()
mCAPE <- numeric()
mHLCY <- numeric()
mCIN <- numeric()
mUSTM <- numeric()
mVSTM <- numeric()
mBS <- numeric()

for(i in 1:length(slug)){
  print(i)
  rb <- brick(paste0("Archive/NARRdata", i, ".grb"))
  CAPE.rl <- raster(rb, layer = 375)
  HLCY.rl <- raster(rb, layer = 323)
#  CAPE.rl <- raster(rb, layer = 315)
  CIN.rl <- raster(rb, layer = 376)
#  CIN.rl <- raster(rb, layer = 316)
  USTM.rl <- raster(rb, layer = 324)
  VSTM.rl <- raster(rb, layer = 325)
  BS.rl <- sqrt(USTM.rl^2 + VSTM.rl^2)
  aCAPE <- c(aCAPE, as.numeric(extract(CAPE.rl, df[i, ], fun = mean)))
  aHLCY <- c(aHLCY, as.numeric(extract(HLCY.rl, df[i, ], fun = mean)))
  aCIN <- c(aCIN, as.numeric(extract(CIN.rl, df[i, ], fun = mean)))
  aUSTM <- c(aUSTM, as.numeric(extract(USTM.rl, df[i, ], fun = mean)))
  aVSTM <- c(aVSTM, as.numeric(extract(VSTM.rl, df[i, ], fun = mean)))
  aBS <- c(aBS, as.numeric(extract(BS.rl, df[i, ], fun = mean)))
  mCAPE <- c(mCAPE, as.numeric(extract(CAPE.rl, df[i, ], fun = max)))
  mHLCY <- c(mHLCY, as.numeric(extract(HLCY.rl, df[i, ], fun = max)))
  mCIN <- c(mCIN, as.numeric(extract(CIN.rl, df[i, ], fun = min)))
  mUSTM <- c(mUSTM, as.numeric(extract(USTM.rl, df[i, ], fun = max)))
  mVSTM <- c(mVSTM, as.numeric(extract(VSTM.rl, df[i, ], fun = max)))
  mBS <- c(mBS, as.numeric(extract(BS.rl, df[i, ], fun = max)))
}
```

Add environmental data values to the group day means data frame.
```{r}
df$aCAPE <- aCAPE
df$aHLCY <- aHLCY
df$aCIN <- aCIN
df$aUSTM <- aUSTM
df$aVSTM <- aVSTM
df$aBS <- aBS
df$mCAPE <- mCAPE
df$mHLCY <- mHLCY
df$mCIN <- mCIN
df$mUSTM <- mUSTM
df$mVSTM <- mVSTM
df$mBS <- mBS
```

Get SST data.
```{r}
SST <- read.table("SST.txt", header = TRUE) %>%
  filter(Year >= 1994 & Year <= 2014)
SST.df <- reshape2::melt(SST, id.vars = "Year")
names(SST.df) <- c("Yr", "mo.abb", "SST")
SST.df$Mo <- as.integer(SST.df$mo.abb)

ENSO <- read.table("ENSO.txt", header = TRUE) %>%
  filter(Year >= 1994)
ENSO.df <- reshape2::melt(ENSO, id.vars = "Year")
names(ENSO.df) <- c("Yr", "mo.abb", "ENSO")
ENSO.df$Mo <- as.integer(ENSO.df$mo.abb)

# df$Mo <- as.integer(df$Month)

df <- left_join(df, SST.df, by = c("Yr", "Mo"))
df <- left_join(df, ENSO.df, by = c("Yr", "Mo"))
```

Save the `df` so we can work on the models without running all the code above.
```{r}
save(df, file = "df.RData")
#load("df.RData")
```

Trends. Leave off 2014 because there is no environmental data after September 2014.
```{r}
df %>%
  filter(nT >= 10, Yr < 2014) %>%
  group_by(Yr) %>%
  summarize(AnnualAvg = mean(aHLCY, na.rm = TRUE)) %>%
ggplot(., aes(x = Yr, y = AnnualAvg)) +
  geom_point() + geom_line() + geom_smooth(method = lm) +
  scale_y_continuous(limits = c(0, NA))
```

Random effects.
```{r}
df %>%
  group_by(Month) %>%
  summarize(mED = mean(aVSTM),
            nT = sum(nT))
```

Models for ATE. Remove row 332 since HLCY is missing for that outbreak.
```{r}
library(lme4)

model1 <- lmer(aUSTM ~ scale(X) + scale(Y) + ENSO + SST + Yr + (1|Month), weights = nT,  data = df)
summary(model1)
confint(model1, method = "Wald")

summary(lmer(log(AvgATE/Area) ~ scale(X) + nT + I(Yr >= 2007) + I(Yr - 2004) + (1|Month), 
             weights = nT, 
             data = df[-332,]))

#Trend .0551

summary(lmer(log(AvgATE/Area) ~ scale(X) + nT + I(Yr >= 2007) + I(Yr - 2004) + (1|Month) + I(aCAPE/1000) * I(aHLCY/10) + I(aCIN/10),
             weights = nT, 
             data = df[-332,]))
#Trend .0417

#confint(model, method = "Wald")
```

Plots for the interaction term.
```{r}
library(interplot)
df$aCAPE2 <- df$aCAPE/1000
df$aHLCY2 <- df$aHLCY/10
model <- lmer(log(AvgATE/Area) ~ scale(X) + nT + I(Yr >= 2007) + I(Yr - 2004) + (1|Month) + aCAPE2 * aHLCY2 + I(aCIN/10),
             weights = nT, 
             data = df[-332,])

interplot(m = model, var1 = "aCAPE2", var2 = "aHLCY2", hist = TRUE) +
    scale_x_continuous(breaks = c(0, 20, 40, 60), labels = c(0, 200, 400, 600)) +
    scale_y_continuous() +
    xlab(expression(paste("Storm Relative Helicity [J/kg]"))) +
    ylab("CAPE's Effect on ATE [%/1000 J/kg]") +
    theme_minimal()
```




Models for casualties.
```{r}
model1b <- lmer(log(GroupDayCas + 1) ~ I(mCAPE/1000) + I(mUSTM/10) + (1|Mo), 
                weights = nT, 
                data = df)
summary(model1b)
```

Observed versus predicted.
```{r}
df$preED <- exp(predict(model0b))
cor(df$preED, df$GroupDayTotalED)
df$preCas <- exp(predict(model1b)) - 1
```

Energy dissipation
```{r}
ggplot(df, aes(x = GroupDayTotalED/10^9, y = preED/10^9, color = log10(GroupDayCas + 1))) +
  scale_color_continuous(guide=FALSE) +
         geom_point() + geom_smooth(method = lm, color = "red", se = FALSE) +
         geom_abline(slope = 1) +
         scale_x_log10(limits = c(1, 300000), breaks = c(1, 10, 100, 1000, 10000, 100000), labels = c("1", "10", "100", "1000", "10,000", "100,000")) +
         scale_y_log10(limits = c(1, 300000), breaks = c(1, 10, 100, 1000, 10000, 100000), labels = c("1", "10", "100", "1000", "10,000", "100,000")) +
  ylab("Predicted Accumulated Tornado Energy [GW]") + xlab("Accumulated Tornado Energy [GW]") +
  theme_minimal()
```

Casualties
```{r}
ggplot(df[df$GroupDayCas > 0, ], aes(x = GroupDayCas, y = preCas)) +
  scale_color_continuous(guide=FALSE) +
         geom_point() + geom_smooth(method = lm, color = "red", se = FALSE) +
         geom_abline(slope = 1) +
         scale_x_log10() +
         scale_y_log10() +
  ylab("Predicted Casualties") + xlab("Observed Casualties") +
  theme_minimal()
```

Plots for the interaction term.
```{r}
library(interplot)
df$mCAPE2 <- df$mCAPE/1000
df$mCIN2 <- df$mCIN/100
model0bX <- lmer(log(GroupDayTotalED) ~ mCAPE2 * mCIN2 + I(mUSTM/10) + I(Yr - 2004) + (1|Mo), 
                weights = nT, 
                data = df)
y <- c(0, 50, 100, 150, 200)
interplot(m = model0bX, var1 = "mCAPE2", var2 = "mCIN2", hist = TRUE, xmin = -3) +
    scale_x_continuous(breaks = seq(-5, 0, 1), 
                       labels = 100 * seq(-5, 0, 1)) +
    scale_y_continuous(breaks = log(y/100 + 1), 
                       labels = y) +
    xlab(expression(paste("CIN [J/kg]"))) +
    ylab("CAPE's Effect on ATE [%/1000 J/kg]") +
    theme_minimal()
```

